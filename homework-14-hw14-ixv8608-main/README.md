# nn_things

Usage: 

	python my_nn.py


@author: Isaias Villalobos
@date: 11/22/2020
@homeworkNumber: 14
@description:   There were several functions that needed to be implemented such as the leaky_relu()
                and the tanh() function, as well as the backward implementations of the functions just mentioned.
                The purpose of doing this is so that the modeling of the data could be done and shown throught matplotlib
                Choosing a good architecture for the neural network would lead to a good model graph being shown and fitting
                the data as good as possible. In order to run this code, which has multiple version, you must do the following:
                To run the first file please do the following:
                    python/python3 my_nn1.py
                    
                To run the second file please do the following:
                    python/python3 my_nn2.py
                
                etc....
                
@notes:         Every np_nn file has a corresponding my_nn file, example: np_nn1.py associates with my_nn1.py
                                                                          np_nn2.py associates with my_nn2.py
                                                                          and so forth
                It seemed like the best choice for the first architecture and second architecture were very similar 
                both using the sigmoid for the bit fit graph of the data points.
                The third architecture changed a little, and the fourth was very interesting where the input/ouput dimensions
                as well as the activation functions, had to be modified to fit the data really well.
                